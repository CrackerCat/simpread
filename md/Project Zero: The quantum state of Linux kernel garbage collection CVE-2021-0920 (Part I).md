> æœ¬æ–‡ç”± [ç®€æ‚¦ SimpRead](http://ksria.com/simpread/) è½¬ç ï¼Œ åŸæ–‡åœ°å€ [googleprojectzero.blogspot.com](https://googleprojectzero.blogspot.com/2022/08/the-quantum-state-of-linux-kernel.html)

> A deep dive into an in-the-wild Android exploit Guest Post by Xingyu Jin, Android Security Research......

A deep dive into an in-the-wild Android exploit

Guest Post by Xingyu Jin, Android Security ResearchThis is part one of a two-part guest blog post, where first we'll look at the [root cause](https://googleprojectzero.github.io/0days-in-the-wild//0day-RCAs/2021/CVE-2021-0920.html) of the CVE-2021-0920 vulnerability. In the second post, we'll dive into the in-the-wild 0-day exploitation of the vulnerability and post-compromise modules.

A surveillance vendor named WintegoÂ has developed an exploit for Linux socket syscall 0-day, CVE-2021-0920, and used it in the wild since at least November 2020 based on the earliest captured sample, until the issue was fixed in November 2021. Â Combined with Chrome and Samsung browser exploits, the vendor was able to remotely root Samsung devices. The fix was released with the [November 2021 Android Security Bulletin](https://source.android.com/security/bulletin/2021-11-01), and applied to Samsung devices in Samsung's December 2021 security update.

Google's Threat Analysis Group (TAG) discovered Samsung browser exploit chains being used in the wild. TAG then performed root cause analysis and discovered that this vulnerability, CVE-2021-0920, was being used to escape the sandbox and elevate privileges. CVE-2021-0920 was reported to Linux/Android anonymously. The Google Android Security Team performedÂ the full deep-dive analysis of the exploit.

This issue was initially discovered in 2016 by a RedHat kernel developer and disclosed in a public email thread, but the Linux kernel community [did not patch](https://patchwork.ozlabs.org/project/netdev/patch/CAOssrKcfncAYsQWkfLGFgoOxAQJVT2hYVWdBA6Cw7hhO8RJ_wQ@mail.gmail.com/)Â the issue until it was re-reported in 2021.

Various Samsung devices were targeted, including the Samsung S10 and S20. By abusing an ephemeral race condition in Linux kernel garbage collection, the exploit code was able to obtain a use-after-free (UAF) in a kernel sk_buffÂ object. The in-the-wild sample could effectively circumvent CONFIG_ARM64_UAO, achieve arbitrary read / write primitives and bypass Samsung RKP to elevate to root.Â Other Android devicesÂ were also vulnerable, but we did not find any exploit samples against them.

Text extracted from captured samples dubbed the vulnerability â€œquantum Linux kernel garbage collectionâ€, which appears to be a fitting title for this blogpost.

CVE-2021-0920 is a use-after-free (UAF) due to a race condition in the garbage collection system for SCM_RIGHTS. SCM_RIGHTSÂ is a control message that allows unix-domain sockets to transmit an open file descriptor from one process to another. In other words, the sender transmits a file descriptor and the receiver then obtains a file descriptor from the sender. This passing of file descriptors adds complexity to reference-counting file structs. To account for this, the Linux kernel community designed a special garbage collection system. CVE-2021-0920 is a vulnerability within this garbage collection system. By winning a race condition during the garbage collection process, an adversary can exploit the UAF on the socket buffer, sk_buffÂ object. In the following sections, weâ€™ll explain the SCM_RIGHTSÂ garbage collection system and the details of the vulnerability. The analysis is based on the Linux 4.14 kernel.

What is SCM_RIGHTS?
-------------------

Linux developers can share file descriptors (fd) from one process to another using the [SCM_RIGHTS datagram with the sendmsg syscall](https://man7.org/linux/man-pages/man7/unix.7.html). When a process passes a file descriptor to another process, SCM_RIGHTSÂ will add a reference to the underlying fileÂ struct. This means that the process that is sending the file descriptors can immediately close the file descriptor on their end, even if the receiving process has not yet accepted and taken ownership of the file descriptors. When the file descriptors are in the â€œqueuedâ€ state (meaning the sender has passed the fd and then closed it, but the receiver has not yet accepted the fd and taken ownership), specialized garbage collection is needed. To track this â€œqueuedâ€ state, this [LWN article](https://lwn.net/Articles/779472/)Â does a great job explaining SCM_RIGHTSÂ reference counting, and it's recommended reading before continuing on with this blogpost.

Sending
-------

As stated previously, a unix domain socket uses the syscall sendmsgÂ to send a file descriptor to another socket. To explain the reference counting that occurs during SCM_RIGHTS, weâ€™ll start from the senderâ€™s point of view. We start with the kernelÂ function unix_stream_sendmsg, which implements the sendmsgÂ syscall. To implement the SCM_RIGHTSÂ functionality, the kernel uses the structure scm_fp_listÂ for managing all the transmitted fileÂ structures. scm_fp_listÂ stores the list of fileÂ pointers to be passed.

structÂ scm_fp_list {

Â  Â  Â  Â  shortÂ Â  Â  Â  Â  Â  Â  Â  Â  Â  count;

Â  Â  Â  Â  shortÂ Â  Â  Â  Â  Â  Â  Â  Â  Â  max;

Â  Â  Â  Â  structÂ user_struct Â  Â  Â *user;

Â  Â  Â  Â  structÂ file Â  Â  Â  Â  Â  Â  *fp[SCM_MAX_FD];

};

unix_stream_sendmsgÂ invokes scm_sendÂ ([af_unix.c#L1886](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/af_unix.c#L1886)) to initialize the scm_fp_listÂ structure, linked by theÂ scm_cookieÂ structure on the stack.

structÂ scm_cookie {

Â  Â  Â  Â  structÂ pid Â  Â  Â  Â  Â  Â  Â *pid;Â Â  Â  Â  Â  Â  /* Skb credentials */

Â  Â  Â  Â  structÂ scm_fp_list Â  Â  Â *fp;Â Â  Â  Â  Â  Â  Â /* Passed files Â  Â  Â  Â  */

Â  Â  Â  Â  structÂ scm_creds Â  Â  Â  Â creds;Â Â  Â  Â  Â  Â /* Skb credentials Â  Â  Â */

#ifdefÂ CONFIG_SECURITY_NETWORK

Â  Â  Â  Â  u32 Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  secid;Â Â  Â  Â  Â  Â /* Passed security ID Â  */

#endif

};

To be more specific, scm_sendÂ â†’ __scm_sendÂ â†’ scm_fp_copyÂ ([scm.c#L68](https://elixir.bootlin.com/linux/v4.14.277/source/net/core/scm.c#L68)) reads the file descriptors from the userspace and initializes scm_cookie->fpÂ which can contain SCM_MAX_FDÂ file structures.

Since the Linux kernel uses the sk_buffÂ (also known as socket buffers or skb) object to manage all types of socket datagrams, the kernel also needs to invoke the unix_scm_to_skbÂ function to link the scm_cookie->fpÂ to a corresponding skbÂ object. This occurs in unix_attach_fdsÂ ([scm.c#L103](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/scm.c#L103)):

â€¦

/*

Â * Need to duplicate file references for the sake of garbage

Â * collection. Â Otherwise a socket in the fps might become a

Â * candidate for GC while the skb is not yet queued.

Â */

UNIXCB(skb).fp =Â scm_fp_dup(scm->fp);

ifÂ (!UNIXCB(skb).fp)

Â  Â  Â  Â  returnÂ -ENOMEM;

â€¦

The scm_fp_dupÂ call in unix_attach_fdsÂ increases the reference count of the file descriptor thatâ€™s being passed so the file is still valid even after the sender closes the transmitted file descriptor later:

structÂ scm_fp_list *scm_fp_dup(structÂ scm_fp_list *fpl)

{

Â  Â  Â  Â  structÂ scm_fp_list *new_fpl;

Â  Â  Â  Â  intÂ i;

Â  Â  Â  Â  ifÂ (!fpl)

Â  Â  Â  Â  Â  Â  Â  Â  returnÂ NULL;

Â  Â  Â  Â  new_fpl =Â kmemdup(fpl,Â offsetof(structÂ scm_fp_list,Â fp[fpl->count]),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  GFP_KERNEL);

Â  Â  Â  Â  ifÂ (new_fpl)Â {

Â  Â  Â  Â  Â  Â  Â  Â  forÂ (i =Â 0;Â i <Â fpl->count;Â i++)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  get_file(fpl->fp[i]);

Â  Â  Â  Â  Â  Â  Â  Â  new_fpl->max =Â new_fpl->count;

Â  Â  Â  Â  Â  Â  Â  Â  new_fpl->user =Â get_uid(fpl->user);

Â  Â  Â  Â  }

Â  Â  Â  Â  returnÂ new_fpl;

}

Letâ€™s examine a concrete example. Assume we have sockets AÂ and B. The AÂ attempts to pass itself to B. After the SCM_RIGHTSÂ datagram is sent, the newly allocated skbÂ from the sender will be appended to the Bâ€™s sk_receive_queueÂ which stores received datagrams:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNWAkA0RVb4goO21_FhJOVV-LSNTfbXV7GKoqH-CUrdMTpDcNUSQxEssrnAVGxC50aK-Z3HfIWeDyCgkr6lb5-a1Ha9Km5ppaHeBzWmLj8NTmZtUjx8J-VzzM1O7mYdjOfw2ErddrslDXw6rDZrs0g1DEC1Ya4VAbkLKKEhZgNPeiSefH-xpv3zDa8/s600/image71.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgNWAkA0RVb4goO21_FhJOVV-LSNTfbXV7GKoqH-CUrdMTpDcNUSQxEssrnAVGxC50aK-Z3HfIWeDyCgkr6lb5-a1Ha9Km5ppaHeBzWmLj8NTmZtUjx8J-VzzM1O7mYdjOfw2ErddrslDXw6rDZrs0g1DEC1Ya4VAbkLKKEhZgNPeiSefH-xpv3zDa8/s1438/image71.png)

sk_buffÂ carries scm_fp_listÂ structure

The reference count of AÂ is incremented to 2 and the reference count of BÂ is still 1.

Receiving
---------

Now, letâ€™s take a look at the receiver side unix_stream_read_genericÂ (we will not discuss the MSG_PEEKÂ flag yet, and focus on the normal [routine](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/af_unix.c#L2445)). First of all, the kernel grabs the current skbÂ from sk_receive_queueÂ using skb_peek. Secondly, since scm_fp_listÂ is attached to the skb, the kernel will call unix_detach_fdsÂ ([link](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/scm.c#L125)) to parse the transmitted file structures from skbÂ and clear the skbÂ from sk_receive_queue:

/* Mark read part of skb as used */

ifÂ (!(flags &Â MSG_PEEK))Â {

Â  Â  Â  Â  UNIXCB(skb).consumed +=Â chunk;

Â  Â  Â  Â  sk_peek_offset_bwd(sk,Â chunk);

Â  Â  Â  Â  ifÂ (UNIXCB(skb).fp)

Â  Â  Â  Â  Â  Â  Â  Â  unix_detach_fds(&scm,Â skb);

Â  Â  Â  Â  ifÂ (unix_skb_len(skb))

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  skb_unlink(skb,Â &sk->sk_receive_queue);

Â  Â  Â  Â  consume_skb(skb);

Â  Â  Â  Â  ifÂ (scm.fp)

Â  Â  Â  Â  Â  Â  Â  Â  break;

The function scm_detach_fdsÂ iterates over the list of passed file descriptors (scm->fp)Â and installs the new file descriptors accordingly for the receiver:

forÂ (i=0,Â cmfptr=(__force intÂ __user *)CMSG_DATA(cm);Â i<fdmax;

Â  Â  Â i++,Â cmfptr++)

{

Â  Â  Â  Â  structÂ socket *sock;

Â  Â  Â  Â  intÂ new_fd;

Â  Â  Â  Â  err =Â security_file_receive(fp[i]);

Â  Â  Â  Â  ifÂ (err)

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  err =Â get_unused_fd_flags(MSG_CMSG_CLOEXEC &Â msg->msg_flags

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ?Â O_CLOEXEC :Â 0);

Â  Â  Â  Â  ifÂ (err <Â 0)

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  new_fd =Â err;

Â  Â  Â  Â  err =Â put_user(new_fd,Â cmfptr);

Â  Â  Â  Â  ifÂ (err)Â {

Â  Â  Â  Â  Â  Â  Â  Â  put_unused_fd(new_fd);

Â  Â  Â  Â  Â  Â  Â  Â  break;

Â  Â  Â  Â  }

Â  Â  Â  Â  /* Bump the usage count and install the file. */

Â  Â  Â  Â  sock =Â sock_from_file(fp[i],Â &err);

Â  Â  Â  Â  ifÂ (sock)Â {

Â  Â  Â  Â  Â  Â  Â  Â  sock_update_netprioidx(&sock->sk->sk_cgrp_data);

Â  Â  Â  Â  Â  Â  Â  Â  sock_update_classid(&sock->sk->sk_cgrp_data);

Â  Â  Â  Â  }

Â  Â  Â  Â  fd_install(new_fd,Â get_file(fp[i]));

}

â€¦

/*

Â * All of the files that fit in the message have had their

Â * usage counts incremented, so we just free the list.

Â */

__scm_destroy(scm);

Once the file descriptors have been installed, __scm_destroyÂ ([link](https://elixir.bootlin.com/linux/v4.14.277/source/net/core/scm.c#L119)) cleans up the allocated scm->fpÂ and decrements the file reference count for every transmitted file structure:

voidÂ __scm_destroy(structÂ scm_cookie *scm)

{

Â  Â  Â  Â  structÂ scm_fp_list *fpl =Â scm->fp;

Â  Â  Â  Â  intÂ i;

Â  Â  Â  Â  ifÂ (fpl)Â {

Â  Â  Â  Â  Â  Â  Â  Â  scm->fp =Â NULL;

Â  Â  Â  Â  Â  Â  Â  Â  forÂ (i=fpl->count-1;Â i>=0;Â i--)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fput(fpl->fp[i]);

Â  Â  Â  Â  Â  Â  Â  Â  free_uid(fpl->user);

Â  Â  Â  Â  Â  Â  Â  Â  kfree(fpl);

Â  Â  Â  Â  }

}

Reference Counting and Inflight Counting
----------------------------------------

As mentioned above, when a file descriptor is passed using SCM_RIGHTS,Â its reference count is immediately incremented. Once the recipient socket has accepted and installed the passed file descriptor, the reference count is then decremented. The complication comes from the â€œmiddleâ€ of this operation: after the file descriptor has been sent, but before the receiver has accepted and installed the file descriptor.

Letâ€™s consider the following scenario:

1.  The process creates sockets AÂ and B.
2.  AÂ sends socket A to socket B.
3.  BÂ sends socket BÂ to socket A.
4.  Close A.
5.  Close B.

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixn2j2I0_3XKxc7uimc_-Bd2F7fUflziTRwXRLeCfzDzrA_GKDsDLvqidYluwq_lGptlzWkZ3DD4f2DGnyjuALHuH46yzHjovkrVdzuG-Ncgi4WphgXf9HK_RPnxB91R07fG7cnyy4wZN-M3qZtb6uKOwarRmxIPdQWbJVA-KQlhKQBBR4EZS6aZDe/s600/image66.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEixn2j2I0_3XKxc7uimc_-Bd2F7fUflziTRwXRLeCfzDzrA_GKDsDLvqidYluwq_lGptlzWkZ3DD4f2DGnyjuALHuH46yzHjovkrVdzuG-Ncgi4WphgXf9HK_RPnxB91R07fG7cnyy4wZN-M3qZtb6uKOwarRmxIPdQWbJVA-KQlhKQBBR4EZS6aZDe/s724/image66.png)

Scenario for reference count cycle

Both sockets are closed prior to accepting the passed file descriptors.The reference counts of AÂ and BÂ are both 1 and can't be further decremented because they were removed from the kernel fd table when the respective processes closed them. Therefore the kernel is unable to release the two skbs and sock structures and an unbreakable cycle is formed. The Linux kernel garbage collection system is designed to prevent memory exhaustion in this particular scenario. The inflightÂ count was implemented to identify potential garbage. Each time the reference count is increased due to an SCM_RIGHTS datagram being sent, the inflightÂ count will also be incremented.

When a file descriptor is sent by SCM_RIGHTSÂ datagram,Â the Linux kernel puts its unix_sockÂ into a global list gc_inflight_list. The kernelÂ increments unix_tot_inflightÂ which counts the total number of inflight sockets. Then, the kernel increments u->inflightÂ which tracks the inflight count for each individual file descriptor in the unix_inflightÂ function ([scm.c#L45](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/scm.c#L45)) invoked from unix_attach_fds:

voidÂ unix_inflight(structÂ user_struct *user,Â structÂ file *fp)

{

Â  Â  Â  Â  structÂ sock *s =Â unix_get_socket(fp);

Â  Â  Â  Â  spin_lock(&unix_gc_lock);

Â  Â  Â  Â  ifÂ (s)Â {

Â  Â  Â  Â  Â  Â  Â  Â  structÂ unix_sock *u =Â unix_sk(s);

Â  Â  Â  Â  Â  Â  Â  Â  ifÂ (atomic_long_inc_return(&u->inflight)Â ==Â 1)Â {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  BUG_ON(!list_empty(&u->link));

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  list_add_tail(&u->link,Â &gc_inflight_list);

Â  Â  Â  Â  Â  Â  Â  Â  }Â elseÂ {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  BUG_ON(list_empty(&u->link));

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  Â  Â  unix_tot_inflight++;

Â  Â  Â  Â  }

Â  Â  Â  Â  user->unix_inflight++;

Â  Â  Â  Â  spin_unlock(&unix_gc_lock);

}

Thus, here is what the sk_buffÂ looks like when transferring a file descriptor within sockets AÂ and B:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7JYdav9RAoJLT1TJAAfsVJ6kudGtVBqb8V8Xs0DjEVDEfouQv3SX06oh4AmpRx8UrMNnjqhe0i0FYB6c2jjNtiwGSa1LpHSsg-0AI270tzyX2ziVEHuOO69qTIYhjj780S0oMvXfrdAuyNImJYtBfZ8oUV869w62NV5wshFX3cM0hpmPW219HZT3u/s600/image64.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7JYdav9RAoJLT1TJAAfsVJ6kudGtVBqb8V8Xs0DjEVDEfouQv3SX06oh4AmpRx8UrMNnjqhe0i0FYB6c2jjNtiwGSa1LpHSsg-0AI270tzyX2ziVEHuOO69qTIYhjj780S0oMvXfrdAuyNImJYtBfZ8oUV869w62NV5wshFX3cM0hpmPW219HZT3u/s756/image64.png)

The inflight count of AÂ is incremented

When the socket file descriptor is received from the other side, the unix_sock.inflightÂ count will be decremented.

Letâ€™s revisit the reference count cycle scenario before the close syscall. This cycle is breakable because any socket files can receive the transmitted file and break the reference cycle:Â 

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgXASWOd1HPgwueBa5J636vqpj3uP4onThAwMEL0K_ZBBh3mUr5WklN_YPLIYzXaKl2aSpzcf_odw0ymXe-k7wewgh592dQfkj8AYn6r4jHVh6TXpML2-zsCyFt6ZjmR8N-hcyCeHIwVDjtgCGuRU-YfulCdMk5GWTu9h7X8N7iuCV7GXkzLOKEwFy9/s600/image70.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgXASWOd1HPgwueBa5J636vqpj3uP4onThAwMEL0K_ZBBh3mUr5WklN_YPLIYzXaKl2aSpzcf_odw0ymXe-k7wewgh592dQfkj8AYn6r4jHVh6TXpML2-zsCyFt6ZjmR8N-hcyCeHIwVDjtgCGuRU-YfulCdMk5GWTu9h7X8N7iuCV7GXkzLOKEwFy9/s704/image70.png)

Breakable cycle before close AÂ and B

After closing both of the file descriptors, the reference count equals the inflight count for each of the socket file descriptors, which is a sign of possible garbage:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiLYC-jGxNwF2UbjAZgIsusMaCUGbBo61ZVRxLljS27iXShVhfCth-_lXBBevW9hyWaIcKBWdkX_6BixTMWNDoE56ZrUFbiKLolrc8orEqPTp_0ITjwRfxUzJZwvaJZWkomMlkM-_Lqr1DdFQVKjnEW_nnuSOz51JCvu-xZDterJudPenVekqGpqP-/s600/image61.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhiLYC-jGxNwF2UbjAZgIsusMaCUGbBo61ZVRxLljS27iXShVhfCth-_lXBBevW9hyWaIcKBWdkX_6BixTMWNDoE56ZrUFbiKLolrc8orEqPTp_0ITjwRfxUzJZwvaJZWkomMlkM-_Lqr1DdFQVKjnEW_nnuSOz51JCvu-xZDterJudPenVekqGpqP-/s700/image61.png)

Unbreakable cycle after close AÂ and B

Now, letâ€™s check another example. Assume we have sockets A, BÂ and ğ›¼:

1.  AÂ sends socket AÂ to socket B.
2.  BÂ sends socket BÂ to socket A.
3.  BÂ sends socket BÂ to socket ğ›¼.
4.  ğ›¼Â sends socket ğ›¼Â to socket B.
5.  Close A.
6.  Close B.

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnuMdkCyfn1Xhzr4NJiNcf3Oxt8ZB8kCVOZEIIVcuTGoHGEq37NFy44gE-wgNaaIZiwoSE0iWSpfifiXtfEMc0qec9_Lih7VE3xqzQJ6PjIGMT7K6Jcz0VLfYELIev025FXRJbnmnKHdChHBnk7DnjFQSRe0kB8k9zoXBP_ZYh7SYlCkQ08qHYhyxY/s600/image68.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnuMdkCyfn1Xhzr4NJiNcf3Oxt8ZB8kCVOZEIIVcuTGoHGEq37NFy44gE-wgNaaIZiwoSE0iWSpfifiXtfEMc0qec9_Lih7VE3xqzQJ6PjIGMT7K6Jcz0VLfYELIev025FXRJbnmnKHdChHBnk7DnjFQSRe0kB8k9zoXBP_ZYh7SYlCkQ08qHYhyxY/s1999/image68.png)

Breakable cycle for A, BÂ andÂ ğ›¼

The cycle is breakable, because we can get newly installed file descriptor Bâ€™Â from the socket file descriptor ğ›¼Â and newly installed file descriptor A'Â from Bâ€™.

Garbage Collection
------------------

A high level view of garbage collection is available from [lwn.net](https://lwn.net/Articles/779472/):

"If, instead, the two counts are equal, that file structure might be part of an unreachable cycle. To determine whether that is the case, the kernel finds the set of all in-flight Unix-domain sockets for which all references are contained in SCM_RIGHTS datagrams (for which f_count and inflight are equal, in other words). It then counts how many references to each of those sockets come from SCM_RIGHTS datagrams attached to sockets in this set. Any socket that has references coming from outside the set is reachable and can be removed from the set. If it is reachable, and if there are any SCM_RIGHTS datagrams waiting to be consumed attached to it, the files contained within that datagram are also reachable and can be removed from the set.

At the end of an iterative process, the kernel may find itself with a set of in-flight Unix-domain sockets that are only referenced by unconsumed (and unconsumable) SCM_RIGHTS datagrams; at this point, it has a cycle of file structures holding the only references to each other. Removing those datagrams from the queue, releasing the references they hold, and discarding them will break the cycle."

To be more specific, the SCM_RIGHTSÂ garbage collection system was developed in order to handle the unbreakable reference cycles. To identify which file descriptors are a part of unbreakable cycles:

1.  Add any unix_sockÂ objects whose reference count equals its inflight count to the gc_candidatesÂ list.
2.  Determine if the socket is referenced by any sockets outside of the gc_candidatesÂ list. If it is then it is reachable, remove it and any sockets it references from the gc_candidatesÂ list. Repeat until no more reachable sockets are found.
3.  After this iterative process, only sockets who are solely referenced by other sockets within the gc_candidatesÂ list are left.

Letâ€™s take a closer look at how this garbage collection process works. First, the kernel finds all the unix_sockÂ objects whose reference counts equals their inflight count and puts them into the gc_candidatesÂ listÂ ([garbage.c#L242)](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/garbage.c#L242):

list_for_each_entry_safe(u,Â next,Â &gc_inflight_list,Â link)Â {

Â  Â  Â  Â  longÂ total_refs;

Â  Â  Â  Â  longÂ inflight_refs;

Â  Â  Â  Â  total_refs =Â file_count(u->sk.sk_socket->file);

Â  Â  Â  Â  inflight_refs =Â atomic_long_read(&u->inflight);

Â  Â  Â  Â  BUG_ON(inflight_refs <Â 1);

Â  Â  Â  Â  BUG_ON(total_refs <Â inflight_refs);

Â  Â  Â  Â  ifÂ (total_refs ==Â inflight_refs)Â {

Â  Â  Â  Â  Â  Â  Â  Â  list_move_tail(&u->link,Â &gc_candidates);

Â  Â  Â  Â  Â  Â  Â  Â  __set_bit(UNIX_GC_CANDIDATE,Â &u->gc_flags);

Â  Â  Â  Â  Â  Â  Â  Â  __set_bit(UNIX_GC_MAYBE_CYCLE,Â &u->gc_flags);

Â  Â  Â  Â  }

}

Next, the kernel removes any sockets that are referenced by other sockets outside of the current gc_candidatesÂ list. To do this, the kernel invokes scan_childrenÂ ([garbage.c#138](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/garbage.c#L138)) along with the function pointer dec_inflightÂ to iterate through each candidateâ€™s sk->receive_queue.Â It decreases the inflight count for each of the passed file descriptors that are themselves candidates for garbage collection ([garbage.c#L261](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/garbage.c#L261)):

/* Now remove all internal in-flight reference to children of

Â * the candidates.

Â */

list_for_each_entry(u,Â &gc_candidates,Â link)

Â  Â  Â  Â  scan_children(&u->sk,Â dec_inflight,Â NULL);

After iterating through all the candidates, if a gc candidate still has a positive inflight count it means that it is referenced by objects outside of the gc_candidatesÂ list and therefore is reachable. These candidates should not be included in the gc_candidatesÂ list so the related inflight counts need to be restored.

To do this, the kernel will put the candidate to not_cycle_listÂ instead and iterates through its receiver queue of each transmitted file in the gc_candidatesÂ listÂ ([garbage.c#L281](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/garbage.c#L281)) and increments the inflight count back. The entire process is done recursively, in order for the garbage collection to avoid purging reachable sockets:

/* Restore the references for children of all candidates,

Â * which have remaining references. Â Do this recursively, so

Â * only those remain, which form cyclic references.

Â *

Â * Use a "cursor" link, to make the list traversal safe, even

Â * though elements might be moved about.

Â */

list_add(&cursor,Â &gc_candidates);

whileÂ (cursor.nextÂ !=Â &gc_candidates)Â {

Â  Â  Â  Â  u =Â list_entry(cursor.next,Â structÂ unix_sock,Â link);

Â  Â  Â  Â  /* Move cursor to after the current position. */

Â  Â  Â  Â  list_move(&cursor,Â &u->link);

Â  Â  Â  Â  ifÂ (atomic_long_read(&u->inflight)Â >Â 0)Â {

Â  Â  Â  Â  Â  Â  Â  Â  list_move_tail(&u->link,Â &not_cycle_list);

Â  Â  Â  Â  Â  Â  Â  Â  __clear_bit(UNIX_GC_MAYBE_CYCLE,Â &u->gc_flags);

Â  Â  Â  Â  Â  Â  Â  Â  scan_children(&u->sk,Â inc_inflight_move_tail,Â NULL);

Â  Â  Â  Â  }

}

list_del(&cursor);

Now gc_candidatesÂ contains only â€œgarbageâ€. The kernel restores original inflight counts from gc_candidates, moves candidates from not_cycle_listÂ back to gc_inflight_listÂ and invokes __skb_queue_purgeÂ for cleaning up garbageÂ ([garbage.c#L306](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/garbage.c#L306)).

/* Now gc_candidates contains only garbage. Â Restore original

Â * inflight counters for these as well, and remove the skbuffs

Â * which are creating the cycle(s).

Â */

skb_queue_head_init(&hitlist);

list_for_each_entry(u,Â &gc_candidates,Â link)

Â  Â  Â  Â  scan_children(&u->sk,Â inc_inflight,Â &hitlist);

/* not_cycle_list contains those sockets which do not make up a

Â * cycle. Â Restore these to the inflight list.

Â */

whileÂ (!list_empty(&not_cycle_list))Â {

Â  Â  Â  Â  u =Â list_entry(not_cycle_list.next,Â structÂ unix_sock,Â link);

Â  Â  Â  Â  __clear_bit(UNIX_GC_CANDIDATE,Â &u->gc_flags);

Â  Â  Â  Â  list_move_tail(&u->link,Â &gc_inflight_list);

}

spin_unlock(&unix_gc_lock);

/* Here we are. Hitlist is filled. Die. */

__skb_queue_purge(&hitlist);

spin_lock(&unix_gc_lock);

__skb_queue_purgeÂ clears every skbÂ from the receiver queue:

/**

Â * Â  Â  Â __skb_queue_purge - empty a list

Â * Â  Â  Â @list: list to empty

Â *

Â * Â  Â  Â Delete all buffers on an &sk_buff list. Each buffer is removed from

Â * Â  Â  Â the list and one reference dropped. This function does not take the

Â * Â  Â  Â list lock and the caller must hold the relevant locks to use it.

Â */

voidÂ skb_queue_purge(structÂ sk_buff_head *list);

staticÂ inlineÂ voidÂ __skb_queue_purge(structÂ sk_buff_head *list)

{

Â  Â  Â  Â  structÂ sk_buff *skb;

Â  Â  Â  Â  whileÂ ((skb =Â __skb_dequeue(list))Â !=Â NULL)

Â  Â  Â  Â  Â  Â  Â  Â  kfree_skb(skb);

}

There are two ways to trigger the garbage collection process:

1.  wait_for_unix_gcÂ is invoked at the beginning of the sendmsgÂ function if there are more than 16,000 inflight sockets
2.  When a socket fileÂ is released by the kernel (i.e., a file descriptor is closed), the kernel will directly invoke unix_gc.

Note that unix_gcÂ is not preemptive. If garbage collection is already in process, the kernel will not perform another unix_gcÂ invocation.

Now, letâ€™s check this example (a breakable cycle) with a pair of sockets f00Â and f01,Â and a single socket ğ›¼:

1.  Socket fâ€¯00Â sends socket fâ€¯00Â to socket fâ€¯01.
2.  Socket fâ€¯01Â sends socket fâ€¯01Â to socket ğ›¼.
3.  Close fâ€¯00.
4.  Close fâ€¯01.

Before starting the garbage collection process, the status of socket file descriptors are:

*   fâ€¯00: ref = 1, inflight = 1
*   fâ€¯01: ref = 1, inflight = 1
*   ğ›¼: ref = 1, inflight = 0

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfD3EkqhRCP3nucxrm7-5h2T0Z0Q9e2xWhLX_CA07nU5IWXOAejwDvqPBd2CeJVLrM5bg502cpkm2noANVBV24QVmHRGA3IkHF_at3u6i2rYCHZH4wpvS5EfIC6ibJgtZb4LSO2IjdNbqw_PawxHzGAI9LtmhXRO5rv8SDTHa5mwncMXptSJmjnBZx/s600/image69.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhfD3EkqhRCP3nucxrm7-5h2T0Z0Q9e2xWhLX_CA07nU5IWXOAejwDvqPBd2CeJVLrM5bg502cpkm2noANVBV24QVmHRGA3IkHF_at3u6i2rYCHZH4wpvS5EfIC6ibJgtZb4LSO2IjdNbqw_PawxHzGAI9LtmhXRO5rv8SDTHa5mwncMXptSJmjnBZx/s834/image69.png)

Breakable cycle by f 00, f 01Â and ğ›¼

During the garbage collection process, f 00Â and f 01Â are considered garbage candidates. The inflight count of f 00Â is dropped to zero, but the count of f 01Â is still 1 because ğ›¼Â is not a candidate. Thus, the kernel will restore the inflight count from f 01â€™sÂ receive queue. As a result, f 00Â and f 01Â are not treated as garbage anymore.

WhenÂ a user receives SCM_RIGHTSÂ message from recvmsgÂ without the MSG_PEEKÂ flag, the kernel will wait until the garbage collection process finishes if it is in progress. However, if the MSG_PEEKÂ flag is on, the kernel will increment the reference count of the transmitted file structures without synchronizing with any ongoing garbage collection process. This may lead to inconsistency of the internal garbage collection state, making the garbage collector mark a non-garbage sock object as garbage to purge.

recvmsg without MSG_PEEK flag
-----------------------------

The kernel functionÂ unix_stream_read_genericÂ ([af_unix.c#L2290](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/af_unix.c#L2290)) parses the SCM_RIGHTSÂ message and manages the file inflight count when the MSG_PEEKÂ flag is NOTÂ set. Then, the function unix_stream_read_genericÂ calls unix_detach_fdsÂ to decrement the inflight count. Then, unix_detach_fdsÂ clears the list of passed file descriptors (scm_fp_list) from the skb:

staticÂ voidÂ unix_detach_fds(structÂ scm_cookie *scm,Â structÂ sk_buff *skb)

{

Â  Â  Â  Â  intÂ i;

Â  Â  Â  Â  scm->fp =Â UNIXCB(skb).fp;

Â  Â  Â  Â  UNIXCB(skb).fp =Â NULL;

Â  Â  Â  Â  forÂ (i =Â scm->fp->count-1;Â i >=Â 0;Â i--)

Â  Â  Â  Â  Â  Â  Â  Â  unix_notinflight(scm->fp->user,Â scm->fp->fp[i]);

}

The unix_notinflightÂ from unix_detach_fdsÂ will reverse the effect of unix_inflightÂ by decrementing the inflight count:

voidÂ unix_notinflight(structÂ user_struct *user,Â structÂ file *fp)

{

Â  Â  Â  Â  structÂ sock *s =Â unix_get_socket(fp);

Â  Â  Â  Â  spin_lock(&unix_gc_lock);

Â  Â  Â  Â  ifÂ (s)Â {

Â  Â  Â  Â  Â  Â  Â  Â  structÂ unix_sock *u =Â unix_sk(s);

Â  Â  Â  Â  Â  Â  Â  Â  BUG_ON(!atomic_long_read(&u->inflight));

Â  Â  Â  Â  Â  Â  Â  Â  BUG_ON(list_empty(&u->link));

Â  Â  Â  Â  Â  Â  Â  Â  ifÂ (atomic_long_dec_and_test(&u->inflight))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  list_del_init(&u->link);

Â  Â  Â  Â  Â  Â  Â  Â  unix_tot_inflight--;

Â  Â  Â  Â  }

Â  Â  Â  Â  user->unix_inflight--;

Â  Â  Â  Â  spin_unlock(&unix_gc_lock);

}

Later skb_unlinkÂ and consume_skbÂ are invoked from unix_stream_read_genericÂ ([af_unix.c#2451](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/af_unix.c#L2451))Â to destroy the current skb. Following the call chain kfree(skb)->__kfree_skb, the kernel will invoke the function pointer skb->destructorÂ ([code](https://elixir.bootlin.com/linux/v4.14.277/source/net/unix/af_unix.c#L1605)) which redirects to unix_destruct_scm:

staticÂ voidÂ unix_destruct_scm(structÂ sk_buff *skb)

{

Â  Â  Â  Â  structÂ scm_cookie scm;

Â  Â  Â  Â  memset(&scm,Â 0,Â sizeof(scm));

Â  Â  Â  Â  scm.pid Â =Â UNIXCB(skb).pid;

Â  Â  Â  Â  ifÂ (UNIXCB(skb).fp)

Â  Â  Â  Â  Â  Â  Â  Â  unix_detach_fds(&scm,Â skb);

Â  Â  Â  Â  /* Alas, it calls VFS */

Â  Â  Â  Â  /* So fscking what? fput() had been SMP-safe since the last Summer */

Â  Â  Â  Â  scm_destroy(&scm);

Â  Â  Â  Â  sock_wfree(skb);

}

In fact, the unix_detach_fdsÂ will not be invoked again here from unix_destruct_scmÂ because UNIXCB(skb).fpÂ is already cleared by unix_detach_fds. Finally, fd_install(new_fd, get_file(fp[i]))Â from scm_detach_fdsÂ is invoked for installing a new file descriptor.

recvmsg with MSG_PEEK flag
--------------------------

The recvmsgÂ process is different if the MSG_PEEKÂ flag is set. The MSG_PEEKÂ flag is used during receive to â€œpeekâ€ at the message, but the data is treated as unread. unix_stream_read_genericÂ will invoke scm_fp_dupÂ instead of unix_detach_fds. This increases the reference count of the inflight file ([af_unix.c#2149](https://android.googlesource.com/kernel/goldfish/+/eee65a1282369eedfcbb664d0c865a0ef3eb7017/net/unix/af_unix.c#2149)):

/* It is questionable, see note in unix_dgram_recvmsg.

Â */

ifÂ (UNIXCB(skb).fp)

Â  Â  Â  Â  scm.fp =Â scm_fp_dup(UNIXCB(skb).fp);

sk_peek_offset_fwd(sk,Â chunk);

ifÂ (UNIXCB(skb).fp)

Â  Â  Â  Â  break;

Because the data should be treated as unread, the skbÂ is not unlinked and consumed when the MSG_PEEKÂ flag is set. However, the receiver will still get a new file descriptor for the inflight socket.

recvmsg Examples
----------------

Letâ€™s see a concrete example. Assume there are the following socket pairs:

*   f 00, f 01
*   f 10, f 11

Now, the program does the following operations:

*   f 00Â â†’ [f 00] â†’ f 01 (means f 00Â sends [f 00] to f 01)
*   f 10Â â†’ [f 00] â†’ f 11
*   Close(f 00)

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhi5B8kJXBAiYH3vq8NcQtmatM_hz8o9KgBZpMbMyd9QwRC84jh-SZo76fLhvSFrRohs4pUhBW48q3fQ0bUu0DlySHyJhDMC69rz8qwEM8nHK4b1RGLMw9QGwPmf4E7iMjo5Noa6eF-GDEuMqa4Gzq0fwiBCXU_x0i_Q7eGd2OqiIbu7lYFFaErVE5o/s600/image62.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhi5B8kJXBAiYH3vq8NcQtmatM_hz8o9KgBZpMbMyd9QwRC84jh-SZo76fLhvSFrRohs4pUhBW48q3fQ0bUu0DlySHyJhDMC69rz8qwEM8nHK4b1RGLMw9QGwPmf4E7iMjo5Noa6eF-GDEuMqa4Gzq0fwiBCXU_x0i_Q7eGd2OqiIbu7lYFFaErVE5o/s1102/image62.png)

Breakable cycle by f 00, f 01, f 10Â andÂ f 11

Here is the status:

*   inflight(f 00) = 2, ref(f 00) = 2
*   inflight(f 01) = 0, ref(f 01) = 1
*   inflight(f 10) = 0, ref(f 10) = 1
*   inflight(f 11) = 0, ref(f 11) = 1

If the garbage collection process happens now, before any recvmsgÂ calls, the kernel will choose f 00Â as the garbage candidate. However, f 00Â will not have the inflight count altered and the kernel will not purge any garbage.

If f 01Â then calls recvmsgÂ withÂ MSG_PEEKÂ flag, the receive queue doesnâ€™t change and the inflight counts are not decremented. f 01Â gets a new file descriptor f 00'Â which increments the reference count on f 00:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhO9D3ODJFXZt6dQmkyP1e7zZe0smN042wAbdy7isVbd407L-oCrSDS9LDCBshKwft2pWiuKHXQBclib4tQFoou-8U14ZNuyeJMRxDjtuFsTk3B_TDHVQNDl5x8aLt09negBlNpoEzrYgybadh-KbAAGu_U4hqaDNLyOpWFbI06Vjfh1kam2JHuD7yH/s600/image63.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhO9D3ODJFXZt6dQmkyP1e7zZe0smN042wAbdy7isVbd407L-oCrSDS9LDCBshKwft2pWiuKHXQBclib4tQFoou-8U14ZNuyeJMRxDjtuFsTk3B_TDHVQNDl5x8aLt09negBlNpoEzrYgybadh-KbAAGu_U4hqaDNLyOpWFbI06Vjfh1kam2JHuD7yH/s1216/image63.png)

MSG_PEEKÂ increment the reference count of f 00Â while the receive queue is not cleared

Status:

*   inflight(f 00) = 2, ref(f 00) = 3
*   inflight(f 01) = 0, ref(f 01) = 1
*   inflight(f 10) = 0, ref(f 10) = 1
*   inflight(f 11) = 0, ref(f 11) = 1

Then, f 01Â calls recvmsgÂ withoutÂ MSG_PEEKÂ flag, f 01â€™s receive queue is removed. f 01Â also fetches a new file descriptor f 00'':

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNsC7ADpPbHG_EVgFzDOGi6oaXluRrxDKc6kaQAkdwadnfFOu4SbwVESi0-SGHDwu9La-ztndastPnhfiocmhd6fmU0mhCy9a5sDosCQu6eW3x_uu7wHGL5d1c0eMTO3inZlhObh4faQkcGU2fM6zd-cXDjbg6fjS6CKUMpT8Sre9XHefE7Exrt04s/s600/image67.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNsC7ADpPbHG_EVgFzDOGi6oaXluRrxDKc6kaQAkdwadnfFOu4SbwVESi0-SGHDwu9La-ztndastPnhfiocmhd6fmU0mhCy9a5sDosCQu6eW3x_uu7wHGL5d1c0eMTO3inZlhObh4faQkcGU2fM6zd-cXDjbg6fjS6CKUMpT8Sre9XHefE7Exrt04s/s1344/image67.png)

The receive queue of f 01Â is cleared and f 01''Â is obtained from f 01

Status:

*   inflight(f 00) = 1, ref(f 00) = 3
*   inflight(f 01) = 0, ref(f 01) = 1
*   inflight(f 10) = 0, ref(f 10) = 1
*   inflight(f 11) = 0, ref(f 11) = 1

UAF Scenario
------------

From a very high level perspective, the internal state of Linux garbage collection can be non-deterministic because MSG_PEEKÂ is not synchronized with the garbage collector. There is a race condition where the garbage collector can treat an inflight socket as a garbage candidate while the file reference is incremented at the same time during the MSG_PEEKÂ receive. As a consequence, the garbage collector may purge the candidate, freeing the socket buffer, while a receiver may install the file descriptor, leading to a UAF on the skbÂ object.

Letâ€™s see how the captured 0-dayÂ sample triggers the bug step by step (simplified version, in reality you may need more threads working together, but it should demonstrate the core idea). First of all, the sample allocates the following socket pairs and single socket ğ›¼:

*   f 00, f 01
*   f 10, f 11
*   f 20, f 21
*   f 30, f 31
*   sockÂ ğ›¼Â (actually there might be even thousands of ğ›¼Â for protracting the garbage collection process in order to evade a BUG_ONÂ check which will be introduced later).

Now, the program does the below operations:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAHUeccUboPeEe8ydW1HHpM2R-iibCZnsJSrhByCsnhQHtW4IJcC_8GEPtO3R3GPV5x2C9xJfxT7l6Z3UoqRcUeMtuf65G9wI2tPnd91q_vO7spVOfZgAwjeC6WCILmjs1ED618PGlxgMp196O3odP-fKaqIloMSEYRNory126HtXPNyyXCUWefJew/s564/image17.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjAHUeccUboPeEe8ydW1HHpM2R-iibCZnsJSrhByCsnhQHtW4IJcC_8GEPtO3R3GPV5x2C9xJfxT7l6Z3UoqRcUeMtuf65G9wI2tPnd91q_vO7spVOfZgAwjeC6WCILmjs1ED618PGlxgMp196O3odP-fKaqIloMSEYRNory126HtXPNyyXCUWefJew/s564/image17.png)

Close the following file descriptors prior to any recvmsgÂ calls:

*   Close(f 00)
*   Close(f 01)
*   Close(f 11)
*   Close(f 10)
*   Close(f 30)
*   Close(f 31)
*   Close(ğ›¼)

Here is the status:

*   inflight(f 00) = NÂ + 1, ref(f 00) = N + 1
*   inflight(f 01) = 2, ref(f 01) = 2
*   inflight(f 10) = 3, ref(f 10) = 3
*   inflight(f 11) = 1, ref(f 11) = 1
*   inflight(f 20) = 0, ref(f 20) = 1
*   inflight(f 21) = 0, ref(f 21) = 1
*   inflight(f 31) = 1, ref(f 31) = 1
*   inflight(ğ›¼) = 1, ref(ğ›¼) = 1

If the garbage collection process happens now, the kernel will do the following scrutiny:

*   List f 00, f 01, f 10, Â f 11, f 31, ğ›¼Â as garbage candidates. Decrease inflight count for the candidate children in each receive queue.
*   Since f 21Â is not considered a candidate, f 11â€™s inflight count is still above zero.
*   Recursively restore the inflight count.
*   Nothing is considered garbage.

A potential skb UAF by race condition can be triggered by:

1.  Call recvmsgÂ with MSG_PEEKÂ flag from f 21Â to get f 11â€™.
2.  Call recvmsgÂ with MSG_PEEKÂ flag from f 11Â to get f 10â€™.
3.  Concurrently do the following operations:

1.  Call recvmsgÂ without MSG_PEEKÂ flag from f 11Â to get f 10â€™â€™.
2.  Call recvmsgÂ with MSG_PEEKÂ flag from f 10â€™

How is it possible? Letâ€™s see a case where the race condition is not hit so there is no UAF:

<table><tbody><tr><td colspan="1" rowspan="1"><p>Thread 0</p></td><td colspan="1" rowspan="1"><p>Thread 1</p></td><td colspan="1" rowspan="1"><p>Thread 2</p></td></tr><tr><td colspan="1" rowspan="1"><p>Call unix_gc</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage0: List f 00, f 01, f 10, &nbsp;f 11, f 31, ğ›¼&nbsp;as garbage candidates.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 21&nbsp;to get f 11â€™</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Increase reference count: scm.fp = scm_fp_dup(UNIXCB(skb).fp);</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage0: decrease inflight count from the child of every garbage candidate</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Status after stage 0:</p><p>inflight(f 00) = 0</p><p>inflight(f 01) = 0</p><p>inflight(f 10) = 0</p><p>inflight(f 11) = 1</p><p>inflight(f 31) = 0</p><p>inflight(ğ›¼) = 0</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage1: Recursively restore inflight count if a candidate still has inflight count.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage1: All inflight counts have been restored.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage2: No garbage, return.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 11&nbsp;to get f 10â€™</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;without MSG_PEEK&nbsp;flag from fâ€¯11&nbsp;to get fâ€¯10â€™â€™</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 10â€™</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Everyone is happy</p></td><td colspan="1" rowspan="1"><p>Everyone is happy</p></td><td colspan="1" rowspan="1"><p>Everyone is happy</p></td></tr></tbody></table>

However, if the second recvmsgÂ occurs just after stage 1 of the garbage collection process, the UAF is triggered:

<table><tbody><tr><td colspan="1" rowspan="1"><p>Thread 0</p></td><td colspan="1" rowspan="1"><p>Thread 1</p></td><td colspan="1" rowspan="1"><p>Thread 2</p></td></tr><tr><td colspan="1" rowspan="1"><p>Call unix_gc</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage0: List f 00, f 01, f 10, &nbsp;f 11, f 31, ğ›¼&nbsp;as garbage candidates.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 21&nbsp;to get f 11â€™</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Increase reference count: scm.fp = scm_fp_dup(UNIXCB(skb).fp);</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage0: decrease inflight count from the child of every garbage candidates</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Status after stage 0:</p><p>inflight(f 00) = 0</p><p>inflight(f 01) = 0</p><p>inflight(f 10) = 0</p><p>inflight(f 11) = 1</p><p>inflight(f 31) = 0</p><p>inflight(ğ›¼) = 0</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage1: Start restoring inflight count.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 11&nbsp;to get f 10â€™</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Call recvmsg&nbsp;without MSG_PEEK&nbsp;flag from fâ€¯11&nbsp;to get fâ€¯10â€™â€™</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>unix_detach_fds: UNIXCB(skb).fp = NULL</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Blocked by spin_lock(&amp;unix_gc_lock)</p></td></tr><tr><td colspan="1" rowspan="1"><p>Stage1: scan_inflight&nbsp;cannot find candidate children from f 11. Thus, the inflight count accidentally remains the same.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage2: f 00, f 01, f 10, f 31, ğ›¼&nbsp;are garbage.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage2: start purging garbage.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Start calling recvmsg&nbsp;with MSG_PEEK&nbsp;flag from f 10â€™, which would expect to receive f 00'</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Get skb = skb_peek(&amp;sk-&gt;sk_receive_queue), skb&nbsp;is going to be freed by thread 0.</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>Stage2: for<img class="" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgRTVI1goYtLkJZYRh0P5Wj_jeCjDeIhbMLEzwbzMCMWdag6uBicpIv7TtDorvArzkMmQGMRq6Ss5WdVDwyKTZE9frPBY44fOF667d2D7rKxarcAfp9x9t-YrNRielyFYOgI0998OI0TplaeHW7CGyz4SAFs2udorAlUMxe4gaCPYqr2zP9AjmKbyip/s260/image18.png">, calls __skb_unlink&nbsp;and kfree_skb&nbsp;later.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>state-&gt;recv_actor(skb, skip, chunk, state)&nbsp;UAF</p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p>GC finished.</p></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Start garbage collection.</p></td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1"><p>Get f 10â€™â€™</p></td></tr></tbody></table>

Therefore, the race condition causes a UAF of the skb object. At first glance, we should blame the second recvmsgÂ syscall because it clears skb.fp, the passed file list.Â However, if the first recvmsgÂ syscall doesnâ€™t set the MSG_PEEKÂ flag, the UAF can be avoided because unix_notinflightÂ is serialized with the garbage collection. In other words, the kernel makes sure the garbage collection is either not processed or finished before decrementing the inflight count and removing the skb. After unix_notinflight, the receiver obtains f11'and inflight sockets don't form an unbreakable cycle.

Since MSG_PEEKÂ is not serialized with the garbage collection, when recvmsgÂ is called with MSG_PEEKÂ set, the kernel still considers f 11Â as a garbage candidate. For this reason, the following next recvmsgÂ will eventually trigger the bug due to the inconsistent state of the garbage collection process.

CVE-2021-0920 was found in 2016
-------------------------------

The vulnerability was [initially reported to the Linux kernel community in 2016](https://patchwork.ozlabs.org/project/netdev/patch/CAOssrKcfncAYsQWkfLGFgoOxAQJVT2hYVWdBA6Cw7hhO8RJ_wQ@mail.gmail.com/). The researcher also provided the correct patch advice but it was not accepted by the Linux kernel community:

[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh8WLJ5TaSrwBSyzsB2cnn3WlhRBqZzDHyOAnU8PWvMGr9d2l85FCYHw8fwiHRmFRMtPBMSe3kcFyISMGzuqmFyc0Ks5gJymqNPxh_kHdy59iHrUXTkpc5MTEyoOSroIHMzmqgQCibycvyxMRR-kUmjKIB3y0kqNHvN1TQULEUY8f04pIe65f-z3l3A/s600/image65.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh8WLJ5TaSrwBSyzsB2cnn3WlhRBqZzDHyOAnU8PWvMGr9d2l85FCYHw8fwiHRmFRMtPBMSe3kcFyISMGzuqmFyc0Ks5gJymqNPxh_kHdy59iHrUXTkpc5MTEyoOSroIHMzmqgQCibycvyxMRR-kUmjKIB3y0kqNHvN1TQULEUY8f04pIe65f-z3l3A/s1202/image65.png)

Patch was not applied in 2016

In theory, anyone who saw this patch might come up with an exploit against the faulty garbage collector.

Patch in 2021
-------------

Letâ€™s check the official [patch](https://lore.kernel.org/lkml/20210802134333.066918619@linuxfoundation.org/)Â for CVE-2021-0920. For the MSG_PEEKÂ branch, it requests theÂ garbage collection lock unix_gc_lockÂ before performing sensitive actionsÂ and immediately releases it afterwards:

â€¦

+Â  Â  Â  Â spin_lock(&unix_gc_lock);

+Â  Â  Â  Â spin_unlock(&unix_gc_lock);

â€¦

The patch is confusing - itâ€™s rare to see such lock usage in software development. Regardless, the MSG_PEEKÂ flag now waits for the completion of the garbage collector, so the UAF issue is resolved.

BUG_ON Added in 2017
--------------------

Andrey Ulanov from Google in 2017 found another issue in unix_gcÂ and provided a fix [commit](https://lore.kernel.org/lkml/20170315031642.19576-1-andreyu@google.com/). Additionally, the patch added a BUG_ONÂ for the inflight count:

voidÂ unix_notinflight(structÂ user_struct *user,Â structÂ file *fp)

Â  Â  Â  Â  ifÂ (s)Â {

Â  Â  Â  Â  Â  Â  Â  Â  structÂ unix_sock *u =Â unix_sk(s);

+Â Â  Â  Â  Â  Â  Â  Â  BUG_ON(!atomic_long_read(&u->inflight));

Â  Â  Â  Â  Â  Â  Â  Â  BUG_ON(list_empty(&u->link));

Â  Â  Â  Â  Â  Â  Â  Â  ifÂ (atomic_long_dec_and_test(&u->inflight))

At first glance, it seems thatÂ the BUG_ONÂ can prevent CVE-2021-0920 from being exploitable. However, if the exploit code can delay garbage collection by crafting a large amount of fake garbage, Â it can waive the BUG_ONÂ check by heap spray.

New Garbage CollectionÂ Discovered in 2021
-----------------------------------------

CVE-2021-4083 deserves an honorable mention: when I discussedÂ CVE-2021-0920 with Jann Horn and Ben Hawkes, Jann found another [issue](https://bugs.chromium.org/p/project-zero/issues/detail?id=2247)Â in the garbage collection, described in the Project Zero blog post [Racing against the clock -- hitting a tiny kernel race window](https://googleprojectzero.blogspot.com/2022/03/racing-against-clock-hitting-tiny.html).

\

To recap, we have discussed the kernel internals of SCM_RIGHTSÂ and the designs and implementations of the Linux kernel garbage collector. Besides, we have analyzed the behavior of MSG_PEEKÂ flag with the recvmsgÂ syscall and how it leads to a kernel UAF by a subtle and arcane race condition.

The bug was spotted in 2016 publicly, but unfortunately the Linux kernel community did not accept the patch at that time. Any threat actors who saw the public email thread may have a chance to develop an LPE exploit against the Linux kernel.

In part two, we'll look at how the vulnerability was exploited and the functionalities of the post compromise modules.